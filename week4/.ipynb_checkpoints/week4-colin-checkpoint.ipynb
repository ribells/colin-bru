{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c4386c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers --update\n",
    "!pip install accelerate\n",
    "# uncomment below cell to train on TPU's\n",
    "#!pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install git+https://github.com/huggingface/accelerate\n",
    "!pip install ml_collections\n",
    "!pip install datasets\n",
    "!pip install pandas-profiling[notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78473417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import ml_collections\n",
    "import datasets\n",
    "import torch\n",
    "import transformers\n",
    "from accelerate import Accelerator, DistributedType\n",
    "from datasets import load_metric, Dataset, DatasetDict\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import emoji\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import re,string, nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "279a0d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ml_collections' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m ml_collections\u001b[38;5;241m.\u001b[39mFrozenConfigDict(cfg_dictionary)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cfg\n\u001b[0;32m---> 27\u001b[0m cfg \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mmodel_config\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_config\u001b[39m():\n\u001b[1;32m      4\u001b[0m     cfg_dictionary \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../input/financial-sentiment-analysis/data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/bert_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta-base\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     }\n\u001b[0;32m---> 24\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m \u001b[43mml_collections\u001b[49m\u001b[38;5;241m.\u001b[39mFrozenConfigDict(cfg_dictionary)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cfg\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ml_collections' is not defined"
     ]
    }
   ],
   "source": [
    "# Setting up the model hyperparameters\n",
    "\n",
    "def model_config():\n",
    "    cfg_dictionary = {\n",
    "        \"data_path\": \"../input/financial-sentiment-analysis/data.csv\",\n",
    "        \"model_path\": \"/kaggle/working/bert_model.h5\",\n",
    "        \"model_type\": \"transformer\",\n",
    "\n",
    "        \"test_size\": 0.1,\n",
    "        \"validation_size\":0.2,\n",
    "        \"train_batch_size\": 32,\n",
    "        \"eval_batch_size\": 32,\n",
    "\n",
    "        \"epochs\": 5,\n",
    "        \"adam_epsilon\": 1e-8,\n",
    "        \"lr\": 3e-5,\n",
    "        \"num_warmup_steps\": 10,\n",
    "\n",
    "        \"max_length\": 128,\n",
    "        \"random_seed\": 42,\n",
    "        \"num_labels\": 3,\n",
    "        \"model_checkpoint\":\"roberta-base\",\n",
    "    }\n",
    "    cfg = ml_collections.FrozenConfigDict(cfg_dictionary)\n",
    "\n",
    "    return cfg\n",
    "cfg = model_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e4f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df,field):\n",
    "    df[field] = df[field].str.replace(r\"http\\S+\",\" \")\n",
    "    df[field] = df[field].str.replace(r\"http\",\" \")\n",
    "    df[field] = df[field].str.replace(r\"@\",\"at\")\n",
    "    df[field] = df[field].str.replace(\"#[A-Za-z0-9_]+\", ' ')\n",
    "    df[field] = df[field].str.replace(r\"[^A-Za-z(),!?@\\'\\\"_\\n]\",\" \")\n",
    "    df[field] = df[field].str.lower()\n",
    "    return df \n",
    "    \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "STOPWORDS.update(['rt', 'mkr', 'didn', 'bc', 'n', 'm','im', 'll', 'y', 've', \n",
    "                      'u', 'ur', 'don','p', 't', 's', 'aren', 'kp', 'o', 'kat', \n",
    "                      'de', 're', 'amp', 'will'])\n",
    "    \n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\",text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub('[^a-zA-Z]',' ',text)\n",
    "    text = re.sub(emoji.get_emoji_regexp(),\"\",text)\n",
    "    text = re.sub(r'[^\\x00-\\x7f]','',text)\n",
    "    text = \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "    text = [lemmatizer.lemmatize(word) for word in text.split() if not word in set(STOPWORDS)]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28786816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_csv(csv_file: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    df[\"label_enc\"] = labelencoder.fit_transform(df[\"Sentiment\"])\n",
    "    df.rename(columns={\"label\": \"label_desc\"}, inplace=True)\n",
    "    df.rename(columns={\"label_enc\": \"labels\"}, inplace=True)\n",
    "    df.drop_duplicates(subset=['Sentence'],keep='first',inplace=True)\n",
    "\n",
    "    cleaned_df = clean_text(df, \"Sentence\")\n",
    "    \n",
    "    if cfg.model_type is not \"transformer\":\n",
    "        cleaned_df[\"Sentence\"] = cleaned_df[\"Sentence\"].apply(preprocess_text)\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d9b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_csv(cfg.data_path)\n",
    "profile = ProfileReport(df, title=\"Financial Sentiment Analysis\")\n",
    "profile.to_notebook_iframe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
